{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pandas, Numpy, and Scikit-Learn are among the most popular libraries for data science and analysis with Python.\n",
    "\n",
    "Numpy is used for lower level scientific computation. Pandas is built on top of Numpy and designed for practical data analysis in Python. Scikit-Learn comes with many machine learning models that you can use out of the box.\n",
    "\n",
    "In this cheat sheet, we’ll summarize some of the most common and useful functionality from these libraries. Let’s jump straight in!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any kind of data analysis starts with getting hold of some data. Pandas gives you plenty of options for getting data into your Python workbook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<b>Importing DataPython</b>\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "    <p>pd.read_csv(filename) <span style = \"Color: red\";># From a CSV file</span></p>\n",
    "    <p>pd.read_table(filename) <span style = \"Color: red\";># From a delimited text file (like TSV)</span></span></p>\n",
    "    <p>pd.read_excel(filename) <span style = \"Color: red\";># From an Excel file</span></p>\n",
    "    <p>pd.read_sql(query, connection_object)<span style = \"Color: red\";> # Reads from a SQL table/database</span></p>\n",
    "    <p>pd.read_json(json_string) <span style = \"Color: red\";># Reads from a JSON formatted string, URL or file.</span></p>\n",
    "    <p>pd.read_html(url)<span style = \"Color: red\";> # Parses an html URL, string or file and extracts tables to a list of dataframes.</span></p>\n",
    "    <p>pd.read_clipboard()<span style = \"Color: red\";> # Takes the contents of your clipboard and passes it to read_table()</span></p>\n",
    "    <p>pd.DataFrame(dict) <span style = \"Color: red\";># From a dict, keys for columns names, values for data as lists</span></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have imported your data into a Pandas dataframe, you can use these methods to get a sense of what the data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exploring DataPython </b>\n",
    "<br>\n",
    "<div>\n",
    "\n",
    "<p>df.shape()<span style = \"Color: red\";># Prints number of rows and columns in dataframe</span></p>\n",
    "<p>df.head(n)<span style = \"Color: red\";># Prints first n rows of the DataFrame</span></p>\n",
    "<p>df.tail(n) <span style = \"Color: red\";># Prints last n rows of the DataFrame</span></span></p>\n",
    "<p>df.info()<span style = \"Color: red\";># Index, Datatype and Memory information</span></p>\n",
    "<p>df.describe()<span style = \"Color: red\";> # Summary statistics for numerical columns</span></span></p>\n",
    "<p>s.value_counts(dropna=False)<span style = \"Color: red\";> # Views unique values and counts</span></p>\n",
    "<p>df.apply(pd.Series.value_counts) <span style = \"Color: red\";># Unique values and counts for all columns</span></p>\n",
    "<p>df.describe() <span style = \"Color: red\";># Summary statistics for numerical columns</span></p>\n",
    "<p>df.mean()<span style = \"Color: red\";> # Returns the mean of all columns</span></p>\n",
    "<p>df.corr()<span style = \"Color: red\";> # Returns the correlation between columns in a DataFrame</span></p>\n",
    "<p>df.count()<span style = \"Color: red\";> # Returns the number of non-null values in each DataFrame column</span></p>\n",
    "<p>df.max() <span style = \"Color: red\";><span style = \"Color: red\";># Returns the highest value in each column</span></p>\n",
    "<p>df.min()<span style = \"Color: red\";> # Returns the lowest value in each column</span></p>\n",
    "<p>df.median() <span style = \"Color: red\";># Returns the median of each column</span></p>\n",
    "<p>df.std()<span style = \"Color: red\";> # Returns the standard deviation of each column</span></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you might need to select a single element or a certain subset of the data to inspect it or perform further analysis. These methods will come in handy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Selecting DataPython</b>\n",
    "<br>\n",
    "<div>\n",
    "<p>df[col] <span style = \"Color: red\";># Returns column with label col as Series</span></p>\n",
    "<p>df[[col1, col2]]<span style = \"Color: red\";> # Returns Columns as a new DataFrame</span></p>\n",
    "<p>s.iloc[0] <span style = \"Color: red\";># Selection by position (selects first element)</span></p>\n",
    "<p>s.loc[0]<span style = \"Color: red\";> # Selection by index (selects element at index 0)</span></p>\n",
    "<p>df.iloc[0,:] <span style = \"Color: red\";># First row</span></p>\n",
    "<p>df.iloc[0,0] <span style = \"Color: red\";># First element of first column</span></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re working with real world data, chances are you’ll need to clean it up. These are some helpful methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data CleaningPython</b>\n",
    "<br>\n",
    "\n",
    "<p>df.columns = ['a','b','c']<span style = \"Color: red\";> # Renames columns</span></p>\n",
    "<p>pd.isnull()<span style = \"Color: red\";> # Checks for null Values, Returns Boolean Array</span></p>\n",
    "<p>pd.notnull()<span style = \"Color: red\";> # Opposite of s.isnull()</span></p>\n",
    "<p>df.dropna() <span style = \"Color: red\";># Drops all rows that contain null valudf.dropna(axis=1) # Drops all columns that contain null values</span></p>\n",
    "<p>df.dropna(axis=1,thresh=n) <span style = \"Color: red\";># Drops all rows have have less than n non null value</span></p>\n",
    "<p>df.fillna(x) <span style = \"Color: red\";># Replaces all null values with x</span></p>\n",
    "<p>s.fillna(s.mean())<span style = \"Color: red\";> # Replaces all null values with the mean (mean can be replaced with almost any function from the statistics section</span>)</p>\n",
    "<p>s.astype(float) <span style = \"Color: red\";># Converts the datatype of the series to float</span></p>\n",
    "<p>s.replace(1,'one') <span style = \"Color: red\";># Replaces all values equal to 1 with 'one'</p>\n",
    "<p>s.replace([1,3],['one','three'])<span style = \"Color: red\";> # Replaces all 1 with 'one' and 3 with 'three'</span></p>\n",
    "<p>df.rename(columns=lambda x: x + 1) <span style = \"Color: red\";># Mass renaming of columns</span></p>\n",
    "<p>df.rename(columns={'old_name': 'new_ name'})<span style = \"Color: red\";> # Selective renaming</span></p>\n",
    "<p>df.set_index('column_one') <span style = \"Color: red\";># Changes the index</span></p>\n",
    "<p>df.rename(index=lambda x: x + 1)<span style = \"Color: red\";> # Mass renaming of index</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter, Sort and Group By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for filtering, sorting and grouping your data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>df1.append(df2) <span style = \"Color: red\";># Adds the rows in df1 to the end of df2 (columns should be identical)</span></span></p>\n",
    "<p>pd.concat([df1, df2],axis=1) <span style = \"Color: red\";># Adds the columns in df1 to the end of df2 (rows should be identical)</span></p>\n",
    "<p>df1.join(df2,on=col1,how='inner') <span style = \"Color: red\";># SQL-style joins the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'<strong> </strong></span></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, when you have produced results with your analysis, there are several ways you can export your data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Writing DataPython</b>\n",
    "<br>\n",
    "\n",
    "<p>df.to_csv(filename)<span style = \"Color: red\";> # Writes to a CSV file</span></p>\n",
    "<p>df.to_excel(filename) <span style = \"Color: red\";># Writes to an Excel file</span></p>\n",
    "<p>df.to_sql(table_name, connection_object)<span style = \"Color: red\";> # Writes to a SQL table</span></p>\n",
    "<p>df.to_json(filename)<span style = \"Color: red\";> # Writes to a file in JSON format</p>\n",
    "<p>df.to_html(filename) <span style = \"Color: red\";><span style = \"Color: red\";># Saves as an HTML table</span></p>\n",
    "<p>df.to_clipboard()<span style = \"Color: red\";> # Writes to the clipboard</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Learn library contains useful methods for training and applying machine learning models. Our <a href=\"https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\"><b>Scikit-Learn tutorial</b></a> provides more context for the code below.\n",
    "\n",
    "For a complete list of the Supervised Learning, Unsupervised Learning, and Dataset Transformation, and Model Evaluation modules in Scikit-Learn, please refer to its <a href = \"https://scikit-learn.org/stable/user_guide.html\"><b>user guide</b></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<strong>Import libraries and modules</strong>\n",
    "<br>\n",
    "<p>import numpy as np</p>\n",
    "<p>import pandas as pd</p>\n",
    " \n",
    "<p>from sklearn.model_selection import train_test_split</p>\n",
    "<p>from sklearn import preprocessing</p>\n",
    "<p>from sklearn.ensemble import RandomForestRegressor</p>\n",
    "<p>from sklearn.pipeline import make_pipeline</p>\n",
    "<p>from sklearn.model_selection import GridSearchCV</p>\n",
    "<p>from sklearn.metrics import mean_squared_error, r2_score</p>\n",
    "<p>from sklearn.externals import joblib </p>\n",
    "<br>\n",
    " \n",
    "<strong>Load red wine data.</strong>\n",
    "<br>\n",
    "<p>dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'</p></p>\n",
    "<p>data = pd.read_csv(dataset_url, sep=';')</p>\n",
    "<br>\n",
    " \n",
    "<strong>Split data into training and test sets</strong>\n",
    "<br>\n",
    "<p>y = data.quality</p>\n",
    "<p>X = data.drop('quality', axis=1)</p>\n",
    "<p>X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)</p>\n",
    "                                                    <br>\n",
    " \n",
    "<strong>Declare data preprocessing steps</strong>\n",
    "<br>\n",
    "<p>pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))</p>\n",
    "                         <br>\n",
    " \n",
    "<strong>Declare hyperparameters to tune</strong>\n",
    "<br>\n",
    "<p>hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}</p>\n",
    "                  <br>\n",
    " \n",
    "<strong>Tune model using cross-validation pipeline</strong>\n",
    "<br>\n",
    "<p>clf = GridSearchCV(pipeline, hyperparameters, cv=10)</p>\n",
    " \n",
    "<p>clf.fit(X_train, y_train)</p>\n",
    "<br>\n",
    " \n",
    "<strong>Refit on the entire training set</strong>\n",
    "<br>\n",
    "<strong>No additional code needed if clf.refit == True (default is True)</strong>\n",
    "<br>\n",
    " \n",
    "<strong>Evaluate model pipeline on test data</strong>\n",
    "<br>\n",
    "<p>pred = clf.predict(X_test)</p>\n",
    "<p>print r2_score(y_test, pred)</p>\n",
    "<p>print mean_squared_error(y_test, pred)</p>\n",
    "<br>\n",
    " \n",
    "<strong>Save model for future use</strong>\n",
    "<br>\n",
    "<p>joblib.dump(clf, 'rf_regressor.pkl')</p>\n",
    "<br>\n",
    "    <strong>To load: clf2 = joblib.load('rf_regressor.pkl')</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Complete Code\n",
    "\n",
    "# Import libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    " \n",
    "# Load red wine data.\n",
    "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(dataset_url, sep=';')\n",
    " \n",
    "# Split data into training and test sets\n",
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)\n",
    " \n",
    "# Declare data preprocessing steps\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))\n",
    " \n",
    "# Declare hyperparameters to tune\n",
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    " \n",
    "# Tune model using cross-validation pipeline\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " \n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# Refit on the entire training set\n",
    "# No additional code needed if clf.refit == True (default is True)\n",
    " \n",
    "# Evaluate model pipeline on test data\n",
    "pred = clf.predict(X_test)\n",
    "print r2_score(y_test, pred)\n",
    "print mean_squared_error(y_test, pred)\n",
    " \n",
    "# Save model for future use\n",
    "joblib.dump(clf, 'rf_regressor.pkl')\n",
    "# To load: clf2 = joblib.load('rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We’ve barely scratching the surface in terms of what you can do with Python and data science, but we hope this cheatsheet has given you a taste of what you can do!\n",
    "\n",
    "This post was kindly provided by our friend Kara Tan. Kara is a cofounder of <a href = \"https://www.altitudelabs.com/\"><b> Altitude Labs</b></a>, a full-service app design and development agency that specializes in data driven design and personalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Additional Resources:<strong>\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li><a href = \"https://elitedatascience.com/machine-learning-projects-for-beginners\"><b>8 Fun Machine Learning Projects for Beginners</b></a></li>\n",
    "\n",
    "<li><a href = \"https://elitedatascience.com/datasets\"><b> Datasets for Data Science and Machine Learning</b></a></li>\n",
    "\n",
    "<li><a href = \"https://elitedatascience.com/beginner-mistakes\"><b>9 Mistakes to Avoid When Starting Your Career in Data Science</b></a></li>\n",
    "<li><a href = \"https://elitedatascience.com/data-science-resources\"><b> Free Data Science Resources for Beginners</b></a></li>\n",
    "<li><a href = \"https://elitedatascience.com/machine-learning-algorithms\"><b>Overview of Modern Machine Learning Algorithms</b></a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
